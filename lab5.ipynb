{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas_ta\n",
      "  Downloading pandas_ta-0.3.14b.tar.gz (115 kB)\n",
      "\u001b[K     |████████████████████████████████| 115 kB 15.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from pandas_ta) (2.0.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->pandas_ta) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas->pandas_ta) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from pandas->pandas_ta) (1.23.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/dist-packages (from pandas->pandas_ta) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.8.2->pandas->pandas_ta) (1.16.0)\n",
      "Building wheels for collected packages: pandas-ta\n",
      "  Building wheel for pandas-ta (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pandas-ta: filename=pandas_ta-0.3.14b0-py3-none-any.whl size=218924 sha256=00344d57bb432d7dee78259ca11f36cb6e6a51de623e560b4e839a10cbc4e226\n",
      "  Stored in directory: /home/user/.cache/pip/wheels/54/4a/75/06b8e63fce6f6d2c1baae5c208edb18eca128407b0c96e1153\n",
      "Successfully built pandas-ta\n",
      "Installing collected packages: pandas-ta\n",
      "Successfully installed pandas-ta-0.3.14b0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas_ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1986-03-13 00:00:00-05:00</th>\n",
       "      <td>0.054893</td>\n",
       "      <td>0.062965</td>\n",
       "      <td>0.054893</td>\n",
       "      <td>0.060274</td>\n",
       "      <td>1031788800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-03-14 00:00:00-05:00</th>\n",
       "      <td>0.060274</td>\n",
       "      <td>0.063504</td>\n",
       "      <td>0.060274</td>\n",
       "      <td>0.062427</td>\n",
       "      <td>308160000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-03-17 00:00:00-05:00</th>\n",
       "      <td>0.062427</td>\n",
       "      <td>0.064042</td>\n",
       "      <td>0.062427</td>\n",
       "      <td>0.063503</td>\n",
       "      <td>133171200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-03-18 00:00:00-05:00</th>\n",
       "      <td>0.063504</td>\n",
       "      <td>0.064042</td>\n",
       "      <td>0.061350</td>\n",
       "      <td>0.061889</td>\n",
       "      <td>67766400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-03-19 00:00:00-05:00</th>\n",
       "      <td>0.061888</td>\n",
       "      <td>0.062427</td>\n",
       "      <td>0.060274</td>\n",
       "      <td>0.060812</td>\n",
       "      <td>47894400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-10 00:00:00-05:00</th>\n",
       "      <td>376.369995</td>\n",
       "      <td>384.170013</td>\n",
       "      <td>376.320007</td>\n",
       "      <td>382.769989</td>\n",
       "      <td>25514200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-11 00:00:00-05:00</th>\n",
       "      <td>386.000000</td>\n",
       "      <td>390.679993</td>\n",
       "      <td>380.380005</td>\n",
       "      <td>384.630005</td>\n",
       "      <td>27850800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-12 00:00:00-05:00</th>\n",
       "      <td>385.489990</td>\n",
       "      <td>388.679993</td>\n",
       "      <td>384.649994</td>\n",
       "      <td>388.470001</td>\n",
       "      <td>21645700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-16 00:00:00-05:00</th>\n",
       "      <td>393.660004</td>\n",
       "      <td>394.029999</td>\n",
       "      <td>387.619995</td>\n",
       "      <td>390.269989</td>\n",
       "      <td>27202300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17 00:00:00-05:00</th>\n",
       "      <td>387.980011</td>\n",
       "      <td>390.109985</td>\n",
       "      <td>384.809998</td>\n",
       "      <td>389.470001</td>\n",
       "      <td>22214400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9538 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close   \n",
       "Date                                                                        \n",
       "1986-03-13 00:00:00-05:00    0.054893    0.062965    0.054893    0.060274  \\\n",
       "1986-03-14 00:00:00-05:00    0.060274    0.063504    0.060274    0.062427   \n",
       "1986-03-17 00:00:00-05:00    0.062427    0.064042    0.062427    0.063503   \n",
       "1986-03-18 00:00:00-05:00    0.063504    0.064042    0.061350    0.061889   \n",
       "1986-03-19 00:00:00-05:00    0.061888    0.062427    0.060274    0.060812   \n",
       "...                               ...         ...         ...         ...   \n",
       "2024-01-10 00:00:00-05:00  376.369995  384.170013  376.320007  382.769989   \n",
       "2024-01-11 00:00:00-05:00  386.000000  390.679993  380.380005  384.630005   \n",
       "2024-01-12 00:00:00-05:00  385.489990  388.679993  384.649994  388.470001   \n",
       "2024-01-16 00:00:00-05:00  393.660004  394.029999  387.619995  390.269989   \n",
       "2024-01-17 00:00:00-05:00  387.980011  390.109985  384.809998  389.470001   \n",
       "\n",
       "                               Volume  Dividends  Stock Splits  \n",
       "Date                                                            \n",
       "1986-03-13 00:00:00-05:00  1031788800        0.0           0.0  \n",
       "1986-03-14 00:00:00-05:00   308160000        0.0           0.0  \n",
       "1986-03-17 00:00:00-05:00   133171200        0.0           0.0  \n",
       "1986-03-18 00:00:00-05:00    67766400        0.0           0.0  \n",
       "1986-03-19 00:00:00-05:00    47894400        0.0           0.0  \n",
       "...                               ...        ...           ...  \n",
       "2024-01-10 00:00:00-05:00    25514200        0.0           0.0  \n",
       "2024-01-11 00:00:00-05:00    27850800        0.0           0.0  \n",
       "2024-01-12 00:00:00-05:00    21645700        0.0           0.0  \n",
       "2024-01-16 00:00:00-05:00    27202300        0.0           0.0  \n",
       "2024-01-17 00:00:00-05:00    22214400        0.0           0.0  \n",
       "\n",
       "[9538 rows x 7 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df = df.ta.ticker(\"MSFT\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>MACD_12_26_9</th>\n",
       "      <th>MACDh_12_26_9</th>\n",
       "      <th>MACDs_12_26_9</th>\n",
       "      <th>BBL_5_2.0</th>\n",
       "      <th>BBM_5_2.0</th>\n",
       "      <th>BBU_5_2.0</th>\n",
       "      <th>BBB_5_2.0</th>\n",
       "      <th>BBP_5_2.0</th>\n",
       "      <th>ADX_14</th>\n",
       "      <th>DMP_14</th>\n",
       "      <th>DMN_14</th>\n",
       "      <th>ATRr_14</th>\n",
       "      <th>T3_10_0.7</th>\n",
       "      <th>MFI_14</th>\n",
       "      <th>OBV</th>\n",
       "      <th>LOGRET_1</th>\n",
       "      <th>ZS_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9538.000000</td>\n",
       "      <td>9538.000000</td>\n",
       "      <td>9538.000000</td>\n",
       "      <td>9538.000000</td>\n",
       "      <td>9.538000e+03</td>\n",
       "      <td>9538.000000</td>\n",
       "      <td>9538.000000</td>\n",
       "      <td>9505.000000</td>\n",
       "      <td>9505.000000</td>\n",
       "      <td>9505.000000</td>\n",
       "      <td>9534.000000</td>\n",
       "      <td>9534.000000</td>\n",
       "      <td>9534.000000</td>\n",
       "      <td>9534.000000</td>\n",
       "      <td>9534.000000</td>\n",
       "      <td>9511.000000</td>\n",
       "      <td>9524.000000</td>\n",
       "      <td>9524.000000</td>\n",
       "      <td>9524.000000</td>\n",
       "      <td>9484.000000</td>\n",
       "      <td>9524.000000</td>\n",
       "      <td>9.538000e+03</td>\n",
       "      <td>9537.000000</td>\n",
       "      <td>9509.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>47.797305</td>\n",
       "      <td>48.296027</td>\n",
       "      <td>47.290184</td>\n",
       "      <td>47.813053</td>\n",
       "      <td>5.728771e+07</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>0.274428</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>0.273116</td>\n",
       "      <td>46.517289</td>\n",
       "      <td>47.751492</td>\n",
       "      <td>48.985695</td>\n",
       "      <td>5.979118</td>\n",
       "      <td>0.526331</td>\n",
       "      <td>24.595378</td>\n",
       "      <td>24.558816</td>\n",
       "      <td>20.951406</td>\n",
       "      <td>1.096677</td>\n",
       "      <td>47.919446</td>\n",
       "      <td>53.180546</td>\n",
       "      <td>1.187471e+10</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.361269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>79.740735</td>\n",
       "      <td>80.541235</td>\n",
       "      <td>78.918280</td>\n",
       "      <td>79.772716</td>\n",
       "      <td>3.815367e+07</td>\n",
       "      <td>0.045582</td>\n",
       "      <td>0.058349</td>\n",
       "      <td>1.558531</td>\n",
       "      <td>0.476564</td>\n",
       "      <td>1.463472</td>\n",
       "      <td>77.616570</td>\n",
       "      <td>79.621251</td>\n",
       "      <td>81.651338</td>\n",
       "      <td>4.476487</td>\n",
       "      <td>0.287177</td>\n",
       "      <td>9.731144</td>\n",
       "      <td>7.802509</td>\n",
       "      <td>7.141366</td>\n",
       "      <td>1.902005</td>\n",
       "      <td>79.614604</td>\n",
       "      <td>15.989710</td>\n",
       "      <td>3.138995e+09</td>\n",
       "      <td>0.021262</td>\n",
       "      <td>1.336135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.054893</td>\n",
       "      <td>0.057045</td>\n",
       "      <td>0.054893</td>\n",
       "      <td>0.055969</td>\n",
       "      <td>2.304000e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.301538</td>\n",
       "      <td>-3.716203</td>\n",
       "      <td>-7.990892</td>\n",
       "      <td>0.054718</td>\n",
       "      <td>0.057691</td>\n",
       "      <td>0.059896</td>\n",
       "      <td>0.278825</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>6.106636</td>\n",
       "      <td>4.549535</td>\n",
       "      <td>2.775363</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.061254</td>\n",
       "      <td>4.488913</td>\n",
       "      <td>1.031789e+09</td>\n",
       "      <td>-0.358332</td>\n",
       "      <td>-4.850175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.449759</td>\n",
       "      <td>3.507880</td>\n",
       "      <td>3.380740</td>\n",
       "      <td>3.443705</td>\n",
       "      <td>3.283830e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.047776</td>\n",
       "      <td>-0.049685</td>\n",
       "      <td>-0.036265</td>\n",
       "      <td>3.322411</td>\n",
       "      <td>3.450850</td>\n",
       "      <td>3.568685</td>\n",
       "      <td>3.083225</td>\n",
       "      <td>0.263632</td>\n",
       "      <td>17.363263</td>\n",
       "      <td>18.987167</td>\n",
       "      <td>15.785414</td>\n",
       "      <td>0.090740</td>\n",
       "      <td>3.542676</td>\n",
       "      <td>41.816782</td>\n",
       "      <td>1.024892e+10</td>\n",
       "      <td>-0.009228</td>\n",
       "      <td>-0.663578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>19.114402</td>\n",
       "      <td>19.314091</td>\n",
       "      <td>18.920980</td>\n",
       "      <td>19.117327</td>\n",
       "      <td>5.038960e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025792</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.025829</td>\n",
       "      <td>18.704830</td>\n",
       "      <td>19.152000</td>\n",
       "      <td>19.612142</td>\n",
       "      <td>4.884135</td>\n",
       "      <td>0.553899</td>\n",
       "      <td>22.744532</td>\n",
       "      <td>23.921960</td>\n",
       "      <td>20.497782</td>\n",
       "      <td>0.433264</td>\n",
       "      <td>19.148081</td>\n",
       "      <td>53.098137</td>\n",
       "      <td>1.281698e+10</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.531041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>36.090293</td>\n",
       "      <td>36.429376</td>\n",
       "      <td>35.739381</td>\n",
       "      <td>36.172991</td>\n",
       "      <td>7.120845e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333121</td>\n",
       "      <td>0.057747</td>\n",
       "      <td>0.327868</td>\n",
       "      <td>35.415247</td>\n",
       "      <td>36.220033</td>\n",
       "      <td>36.959884</td>\n",
       "      <td>7.591662</td>\n",
       "      <td>0.785736</td>\n",
       "      <td>30.095507</td>\n",
       "      <td>29.501733</td>\n",
       "      <td>25.621968</td>\n",
       "      <td>0.855765</td>\n",
       "      <td>36.511833</td>\n",
       "      <td>64.408897</td>\n",
       "      <td>1.392714e+10</td>\n",
       "      <td>0.011268</td>\n",
       "      <td>1.398892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>393.660004</td>\n",
       "      <td>394.029999</td>\n",
       "      <td>387.619995</td>\n",
       "      <td>390.269989</td>\n",
       "      <td>1.031789e+09</td>\n",
       "      <td>3.080000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.676085</td>\n",
       "      <td>3.071273</td>\n",
       "      <td>11.010593</td>\n",
       "      <td>381.298590</td>\n",
       "      <td>387.121997</td>\n",
       "      <td>394.499850</td>\n",
       "      <td>74.354310</td>\n",
       "      <td>0.999614</td>\n",
       "      <td>64.231954</td>\n",
       "      <td>58.396873</td>\n",
       "      <td>51.049875</td>\n",
       "      <td>10.385453</td>\n",
       "      <td>381.168598</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.594408e+10</td>\n",
       "      <td>0.178692</td>\n",
       "      <td>4.398206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open         High          Low        Close        Volume   \n",
       "count  9538.000000  9538.000000  9538.000000  9538.000000  9.538000e+03  \\\n",
       "mean     47.797305    48.296027    47.290184    47.813053  5.728771e+07   \n",
       "std      79.740735    80.541235    78.918280    79.772716  3.815367e+07   \n",
       "min       0.054893     0.057045     0.054893     0.055969  2.304000e+06   \n",
       "25%       3.449759     3.507880     3.380740     3.443705  3.283830e+07   \n",
       "50%      19.114402    19.314091    18.920980    19.117327  5.038960e+07   \n",
       "75%      36.090293    36.429376    35.739381    36.172991  7.120845e+07   \n",
       "max     393.660004   394.029999   387.619995   390.269989  1.031789e+09   \n",
       "\n",
       "         Dividends  Stock Splits  MACD_12_26_9  MACDh_12_26_9  MACDs_12_26_9   \n",
       "count  9538.000000   9538.000000   9505.000000    9505.000000    9505.000000  \\\n",
       "mean      0.002866      0.001782      0.274428       0.001312       0.273116   \n",
       "std       0.045582      0.058349      1.558531       0.476564       1.463472   \n",
       "min       0.000000      0.000000     -9.301538      -3.716203      -7.990892   \n",
       "25%       0.000000      0.000000     -0.047776      -0.049685      -0.036265   \n",
       "50%       0.000000      0.000000      0.025792       0.000255       0.025829   \n",
       "75%       0.000000      0.000000      0.333121       0.057747       0.327868   \n",
       "max       3.080000      2.000000     11.676085       3.071273      11.010593   \n",
       "\n",
       "         BBL_5_2.0    BBM_5_2.0    BBU_5_2.0    BBB_5_2.0    BBP_5_2.0   \n",
       "count  9534.000000  9534.000000  9534.000000  9534.000000  9534.000000  \\\n",
       "mean     46.517289    47.751492    48.985695     5.979118     0.526331   \n",
       "std      77.616570    79.621251    81.651338     4.476487     0.287177   \n",
       "min       0.054718     0.057691     0.059896     0.278825     0.000480   \n",
       "25%       3.322411     3.450850     3.568685     3.083225     0.263632   \n",
       "50%      18.704830    19.152000    19.612142     4.884135     0.553899   \n",
       "75%      35.415247    36.220033    36.959884     7.591662     0.785736   \n",
       "max     381.298590   387.121997   394.499850    74.354310     0.999614   \n",
       "\n",
       "            ADX_14       DMP_14       DMN_14      ATRr_14    T3_10_0.7   \n",
       "count  9511.000000  9524.000000  9524.000000  9524.000000  9484.000000  \\\n",
       "mean     24.595378    24.558816    20.951406     1.096677    47.919446   \n",
       "std       9.731144     7.802509     7.141366     1.902005    79.614604   \n",
       "min       6.106636     4.549535     2.775363     0.001513     0.061254   \n",
       "25%      17.363263    18.987167    15.785414     0.090740     3.542676   \n",
       "50%      22.744532    23.921960    20.497782     0.433264    19.148081   \n",
       "75%      30.095507    29.501733    25.621968     0.855765    36.511833   \n",
       "max      64.231954    58.396873    51.049875    10.385453   381.168598   \n",
       "\n",
       "            MFI_14           OBV     LOGRET_1        ZS_30  \n",
       "count  9524.000000  9.538000e+03  9537.000000  9509.000000  \n",
       "mean     53.180546  1.187471e+10     0.000920     0.361269  \n",
       "std      15.989710  3.138995e+09     0.021262     1.336135  \n",
       "min       4.488913  1.031789e+09    -0.358332    -4.850175  \n",
       "25%      41.816782  1.024892e+10    -0.009228    -0.663578  \n",
       "50%      53.098137  1.281698e+10     0.000365     0.531041  \n",
       "75%      64.408897  1.392714e+10     0.011268     1.398892  \n",
       "max     100.000000  1.594408e+10     0.178692     4.398206  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create your own Custom Strategy\n",
    "CustomStrategy = ta.Strategy(\n",
    "    name=\"My Custom Strategy\",\n",
    "    ta=[\n",
    "        {\"kind\": \"macd\"},\n",
    "        {\"kind\": \"bbands\"},\n",
    "        {\"kind\": \"adx\"},\n",
    "        {\"kind\": \"atr\"},\n",
    "        {\"kind\": \"t3\"},\n",
    "        {\"kind\": \"mfi\"},\n",
    "        {\"kind\": \"obv\"},\n",
    "        {\"kind\": \"log_return\"}, \n",
    "        {\"kind\": \"zscore\"},\n",
    "    ]\n",
    ")\n",
    "# To run your \"Custom Strategy\"\n",
    "df.ta.strategy(CustomStrategy)\n",
    "# df.ta.strategy(exclude=['mcgd'])\n",
    "\n",
    "pd.options.display.max_columns = df.shape[1]\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>MACD_12_26_9</th>\n",
       "      <th>MACDh_12_26_9</th>\n",
       "      <th>MACDs_12_26_9</th>\n",
       "      <th>BBL_5_2.0</th>\n",
       "      <th>BBM_5_2.0</th>\n",
       "      <th>BBU_5_2.0</th>\n",
       "      <th>BBB_5_2.0</th>\n",
       "      <th>BBP_5_2.0</th>\n",
       "      <th>ADX_14</th>\n",
       "      <th>DMP_14</th>\n",
       "      <th>DMN_14</th>\n",
       "      <th>ATRr_14</th>\n",
       "      <th>T3_10_0.7</th>\n",
       "      <th>MFI_14</th>\n",
       "      <th>OBV</th>\n",
       "      <th>LOGRET_1</th>\n",
       "      <th>ZS_30</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1986-05-30 00:00:00-04:00</th>\n",
       "      <td>0.073190</td>\n",
       "      <td>0.076419</td>\n",
       "      <td>0.073190</td>\n",
       "      <td>0.075343</td>\n",
       "      <td>27072000</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.001306</td>\n",
       "      <td>0.064980</td>\n",
       "      <td>0.070930</td>\n",
       "      <td>0.076880</td>\n",
       "      <td>16.777682</td>\n",
       "      <td>0.870831</td>\n",
       "      <td>26.385134</td>\n",
       "      <td>47.632254</td>\n",
       "      <td>13.121785</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>0.068933</td>\n",
       "      <td>60.188217</td>\n",
       "      <td>1.456416e+09</td>\n",
       "      <td>0.036365</td>\n",
       "      <td>2.284042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-06-02 00:00:00-04:00</th>\n",
       "      <td>0.075343</td>\n",
       "      <td>0.075343</td>\n",
       "      <td>0.073190</td>\n",
       "      <td>0.073190</td>\n",
       "      <td>19728000</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.067895</td>\n",
       "      <td>0.072222</td>\n",
       "      <td>0.076549</td>\n",
       "      <td>11.982635</td>\n",
       "      <td>0.611955</td>\n",
       "      <td>28.659023</td>\n",
       "      <td>43.877531</td>\n",
       "      <td>12.087522</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>0.069342</td>\n",
       "      <td>53.286989</td>\n",
       "      <td>1.436688e+09</td>\n",
       "      <td>-0.028986</td>\n",
       "      <td>1.489618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-06-03 00:00:00-04:00</th>\n",
       "      <td>0.073190</td>\n",
       "      <td>0.073190</td>\n",
       "      <td>0.072114</td>\n",
       "      <td>0.073190</td>\n",
       "      <td>5011200</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.070326</td>\n",
       "      <td>0.073083</td>\n",
       "      <td>0.075840</td>\n",
       "      <td>7.544699</td>\n",
       "      <td>0.519540</td>\n",
       "      <td>29.930811</td>\n",
       "      <td>42.064779</td>\n",
       "      <td>15.665549</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>0.069848</td>\n",
       "      <td>51.412590</td>\n",
       "      <td>1.436688e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.422994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-06-04 00:00:00-04:00</th>\n",
       "      <td>0.073190</td>\n",
       "      <td>0.073729</td>\n",
       "      <td>0.072114</td>\n",
       "      <td>0.072652</td>\n",
       "      <td>4723200</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>0.071410</td>\n",
       "      <td>0.073406</td>\n",
       "      <td>0.075402</td>\n",
       "      <td>5.438742</td>\n",
       "      <td>0.311294</td>\n",
       "      <td>31.251844</td>\n",
       "      <td>41.517547</td>\n",
       "      <td>14.695178</td>\n",
       "      <td>0.001895</td>\n",
       "      <td>0.070388</td>\n",
       "      <td>54.390528</td>\n",
       "      <td>1.431965e+09</td>\n",
       "      <td>-0.007379</td>\n",
       "      <td>1.223147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-06-05 00:00:00-04:00</th>\n",
       "      <td>0.072652</td>\n",
       "      <td>0.073729</td>\n",
       "      <td>0.072114</td>\n",
       "      <td>0.073729</td>\n",
       "      <td>13708800</td>\n",
       "      <td>0.001937</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.071769</td>\n",
       "      <td>0.073621</td>\n",
       "      <td>0.075473</td>\n",
       "      <td>5.030303</td>\n",
       "      <td>0.529064</td>\n",
       "      <td>32.471282</td>\n",
       "      <td>38.922146</td>\n",
       "      <td>13.776521</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.070941</td>\n",
       "      <td>56.325592</td>\n",
       "      <td>1.445674e+09</td>\n",
       "      <td>0.014705</td>\n",
       "      <td>1.659402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-10 00:00:00-05:00</th>\n",
       "      <td>376.369995</td>\n",
       "      <td>384.170013</td>\n",
       "      <td>376.320007</td>\n",
       "      <td>382.769989</td>\n",
       "      <td>25514200</td>\n",
       "      <td>2.020107</td>\n",
       "      <td>0.159864</td>\n",
       "      <td>1.860243</td>\n",
       "      <td>362.611085</td>\n",
       "      <td>373.788000</td>\n",
       "      <td>384.964916</td>\n",
       "      <td>5.980350</td>\n",
       "      <td>0.901810</td>\n",
       "      <td>18.443049</td>\n",
       "      <td>27.648576</td>\n",
       "      <td>15.088832</td>\n",
       "      <td>5.726690</td>\n",
       "      <td>372.560493</td>\n",
       "      <td>62.912173</td>\n",
       "      <td>1.553494e+10</td>\n",
       "      <td>0.018404</td>\n",
       "      <td>2.396512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-11 00:00:00-05:00</th>\n",
       "      <td>386.000000</td>\n",
       "      <td>390.679993</td>\n",
       "      <td>380.380005</td>\n",
       "      <td>384.630005</td>\n",
       "      <td>27850800</td>\n",
       "      <td>2.708281</td>\n",
       "      <td>0.678430</td>\n",
       "      <td>2.029851</td>\n",
       "      <td>365.000226</td>\n",
       "      <td>377.126001</td>\n",
       "      <td>389.251776</td>\n",
       "      <td>6.430623</td>\n",
       "      <td>0.809424</td>\n",
       "      <td>20.081542</td>\n",
       "      <td>31.969886</td>\n",
       "      <td>13.254964</td>\n",
       "      <td>6.053355</td>\n",
       "      <td>373.110678</td>\n",
       "      <td>63.237140</td>\n",
       "      <td>1.556279e+10</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>2.740712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-12 00:00:00-05:00</th>\n",
       "      <td>385.489990</td>\n",
       "      <td>388.679993</td>\n",
       "      <td>384.649994</td>\n",
       "      <td>388.470001</td>\n",
       "      <td>21645700</td>\n",
       "      <td>3.522909</td>\n",
       "      <td>1.194447</td>\n",
       "      <td>2.328462</td>\n",
       "      <td>370.736007</td>\n",
       "      <td>381.270001</td>\n",
       "      <td>391.803995</td>\n",
       "      <td>5.525740</td>\n",
       "      <td>0.841751</td>\n",
       "      <td>21.602999</td>\n",
       "      <td>30.405081</td>\n",
       "      <td>12.606183</td>\n",
       "      <td>5.910257</td>\n",
       "      <td>374.104664</td>\n",
       "      <td>63.845458</td>\n",
       "      <td>1.558443e+10</td>\n",
       "      <td>0.009934</td>\n",
       "      <td>3.060262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-16 00:00:00-05:00</th>\n",
       "      <td>393.660004</td>\n",
       "      <td>394.029999</td>\n",
       "      <td>387.619995</td>\n",
       "      <td>390.269989</td>\n",
       "      <td>27202300</td>\n",
       "      <td>4.264592</td>\n",
       "      <td>1.548904</td>\n",
       "      <td>2.715688</td>\n",
       "      <td>374.272147</td>\n",
       "      <td>384.385999</td>\n",
       "      <td>394.499850</td>\n",
       "      <td>5.262341</td>\n",
       "      <td>0.790888</td>\n",
       "      <td>23.599173</td>\n",
       "      <td>34.490740</td>\n",
       "      <td>11.635467</td>\n",
       "      <td>5.945953</td>\n",
       "      <td>375.516293</td>\n",
       "      <td>65.211231</td>\n",
       "      <td>1.561164e+10</td>\n",
       "      <td>0.004623</td>\n",
       "      <td>2.889719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17 00:00:00-05:00</th>\n",
       "      <td>387.980011</td>\n",
       "      <td>390.109985</td>\n",
       "      <td>384.809998</td>\n",
       "      <td>389.470001</td>\n",
       "      <td>22214400</td>\n",
       "      <td>4.733267</td>\n",
       "      <td>1.614063</td>\n",
       "      <td>3.119204</td>\n",
       "      <td>381.298590</td>\n",
       "      <td>387.121997</td>\n",
       "      <td>392.945404</td>\n",
       "      <td>3.008564</td>\n",
       "      <td>0.701601</td>\n",
       "      <td>24.672386</td>\n",
       "      <td>32.215183</td>\n",
       "      <td>14.263271</td>\n",
       "      <td>5.911242</td>\n",
       "      <td>377.221379</td>\n",
       "      <td>58.932657</td>\n",
       "      <td>1.558942e+10</td>\n",
       "      <td>-0.002052</td>\n",
       "      <td>2.382524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9484 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close   \n",
       "Date                                                                        \n",
       "1986-05-30 00:00:00-04:00    0.073190    0.076419    0.073190    0.075343  \\\n",
       "1986-06-02 00:00:00-04:00    0.075343    0.075343    0.073190    0.073190   \n",
       "1986-06-03 00:00:00-04:00    0.073190    0.073190    0.072114    0.073190   \n",
       "1986-06-04 00:00:00-04:00    0.073190    0.073729    0.072114    0.072652   \n",
       "1986-06-05 00:00:00-04:00    0.072652    0.073729    0.072114    0.073729   \n",
       "...                               ...         ...         ...         ...   \n",
       "2024-01-10 00:00:00-05:00  376.369995  384.170013  376.320007  382.769989   \n",
       "2024-01-11 00:00:00-05:00  386.000000  390.679993  380.380005  384.630005   \n",
       "2024-01-12 00:00:00-05:00  385.489990  388.679993  384.649994  388.470001   \n",
       "2024-01-16 00:00:00-05:00  393.660004  394.029999  387.619995  390.269989   \n",
       "2024-01-17 00:00:00-05:00  387.980011  390.109985  384.809998  389.470001   \n",
       "\n",
       "                             Volume  MACD_12_26_9  MACDh_12_26_9   \n",
       "Date                                                               \n",
       "1986-05-30 00:00:00-04:00  27072000      0.001668       0.000362  \\\n",
       "1986-06-02 00:00:00-04:00  19728000      0.001796       0.000392   \n",
       "1986-06-03 00:00:00-04:00   5011200      0.001876       0.000378   \n",
       "1986-06-04 00:00:00-04:00   4723200      0.001874       0.000301   \n",
       "1986-06-05 00:00:00-04:00  13708800      0.001937       0.000291   \n",
       "...                             ...           ...            ...   \n",
       "2024-01-10 00:00:00-05:00  25514200      2.020107       0.159864   \n",
       "2024-01-11 00:00:00-05:00  27850800      2.708281       0.678430   \n",
       "2024-01-12 00:00:00-05:00  21645700      3.522909       1.194447   \n",
       "2024-01-16 00:00:00-05:00  27202300      4.264592       1.548904   \n",
       "2024-01-17 00:00:00-05:00  22214400      4.733267       1.614063   \n",
       "\n",
       "                           MACDs_12_26_9   BBL_5_2.0   BBM_5_2.0   BBU_5_2.0   \n",
       "Date                                                                           \n",
       "1986-05-30 00:00:00-04:00       0.001306    0.064980    0.070930    0.076880  \\\n",
       "1986-06-02 00:00:00-04:00       0.001404    0.067895    0.072222    0.076549   \n",
       "1986-06-03 00:00:00-04:00       0.001498    0.070326    0.073083    0.075840   \n",
       "1986-06-04 00:00:00-04:00       0.001573    0.071410    0.073406    0.075402   \n",
       "1986-06-05 00:00:00-04:00       0.001646    0.071769    0.073621    0.075473   \n",
       "...                                  ...         ...         ...         ...   \n",
       "2024-01-10 00:00:00-05:00       1.860243  362.611085  373.788000  384.964916   \n",
       "2024-01-11 00:00:00-05:00       2.029851  365.000226  377.126001  389.251776   \n",
       "2024-01-12 00:00:00-05:00       2.328462  370.736007  381.270001  391.803995   \n",
       "2024-01-16 00:00:00-05:00       2.715688  374.272147  384.385999  394.499850   \n",
       "2024-01-17 00:00:00-05:00       3.119204  381.298590  387.121997  392.945404   \n",
       "\n",
       "                           BBB_5_2.0  BBP_5_2.0     ADX_14     DMP_14   \n",
       "Date                                                                    \n",
       "1986-05-30 00:00:00-04:00  16.777682   0.870831  26.385134  47.632254  \\\n",
       "1986-06-02 00:00:00-04:00  11.982635   0.611955  28.659023  43.877531   \n",
       "1986-06-03 00:00:00-04:00   7.544699   0.519540  29.930811  42.064779   \n",
       "1986-06-04 00:00:00-04:00   5.438742   0.311294  31.251844  41.517547   \n",
       "1986-06-05 00:00:00-04:00   5.030303   0.529064  32.471282  38.922146   \n",
       "...                              ...        ...        ...        ...   \n",
       "2024-01-10 00:00:00-05:00   5.980350   0.901810  18.443049  27.648576   \n",
       "2024-01-11 00:00:00-05:00   6.430623   0.809424  20.081542  31.969886   \n",
       "2024-01-12 00:00:00-05:00   5.525740   0.841751  21.602999  30.405081   \n",
       "2024-01-16 00:00:00-05:00   5.262341   0.790888  23.599173  34.490740   \n",
       "2024-01-17 00:00:00-05:00   3.008564   0.701601  24.672386  32.215183   \n",
       "\n",
       "                              DMN_14   ATRr_14   T3_10_0.7     MFI_14   \n",
       "Date                                                                    \n",
       "1986-05-30 00:00:00-04:00  13.121785  0.001968    0.068933  60.188217  \\\n",
       "1986-06-02 00:00:00-04:00  12.087522  0.001981    0.069342  53.286989   \n",
       "1986-06-03 00:00:00-04:00  15.665549  0.001917    0.069848  51.412590   \n",
       "1986-06-04 00:00:00-04:00  14.695178  0.001895    0.070388  54.390528   \n",
       "1986-06-05 00:00:00-04:00  13.776521  0.001875    0.070941  56.325592   \n",
       "...                              ...       ...         ...        ...   \n",
       "2024-01-10 00:00:00-05:00  15.088832  5.726690  372.560493  62.912173   \n",
       "2024-01-11 00:00:00-05:00  13.254964  6.053355  373.110678  63.237140   \n",
       "2024-01-12 00:00:00-05:00  12.606183  5.910257  374.104664  63.845458   \n",
       "2024-01-16 00:00:00-05:00  11.635467  5.945953  375.516293  65.211231   \n",
       "2024-01-17 00:00:00-05:00  14.263271  5.911242  377.221379  58.932657   \n",
       "\n",
       "                                    OBV  LOGRET_1     ZS_30  \n",
       "Date                                                         \n",
       "1986-05-30 00:00:00-04:00  1.456416e+09  0.036365  2.284042  \n",
       "1986-06-02 00:00:00-04:00  1.436688e+09 -0.028986  1.489618  \n",
       "1986-06-03 00:00:00-04:00  1.436688e+09  0.000000  1.422994  \n",
       "1986-06-04 00:00:00-04:00  1.431965e+09 -0.007379  1.223147  \n",
       "1986-06-05 00:00:00-04:00  1.445674e+09  0.014705  1.659402  \n",
       "...                                 ...       ...       ...  \n",
       "2024-01-10 00:00:00-05:00  1.553494e+10  0.018404  2.396512  \n",
       "2024-01-11 00:00:00-05:00  1.556279e+10  0.004848  2.740712  \n",
       "2024-01-12 00:00:00-05:00  1.558443e+10  0.009934  3.060262  \n",
       "2024-01-16 00:00:00-05:00  1.561164e+10  0.004623  2.889719  \n",
       "2024-01-17 00:00:00-05:00  1.558942e+10 -0.002052  2.382524  \n",
       "\n",
       "[9484 rows x 22 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.dropna(axis=1, inplace=True)\n",
    "df.dropna(axis=0, inplace=True)\n",
    "df.drop(columns=['Dividends', 'Stock Splits'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cor = df.corr()\n",
    "sns.heatmap(cor, cmap=plt.cm.Reds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "\n",
    "target = ((df['Close'].shift(-1) - df['Close']) / df['Close'] * 100)\n",
    "# df['Volume'] = zscore(df['Volume'].to_numpy())\n",
    "# df['OBV'] = zscore(df['OBV'].to_numpy())\n",
    "# df.apply(zscore)\n",
    "for c in df.columns.tolist():\n",
    "    df[c] = zscore(df[c])\n",
    "df['Target'] = target\n",
    "df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[:'2022-03-31']\n",
    "test_df = df['2022-04-01':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>MACD_12_26_9</th>\n",
       "      <th>MACDh_12_26_9</th>\n",
       "      <th>MACDs_12_26_9</th>\n",
       "      <th>BBL_5_2.0</th>\n",
       "      <th>BBM_5_2.0</th>\n",
       "      <th>BBU_5_2.0</th>\n",
       "      <th>BBB_5_2.0</th>\n",
       "      <th>BBP_5_2.0</th>\n",
       "      <th>ADX_14</th>\n",
       "      <th>DMP_14</th>\n",
       "      <th>DMN_14</th>\n",
       "      <th>ATRr_14</th>\n",
       "      <th>T3_10_0.7</th>\n",
       "      <th>MFI_14</th>\n",
       "      <th>OBV</th>\n",
       "      <th>LOGRET_1</th>\n",
       "      <th>ZS_30</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-04-01 00:00:00-04:00</th>\n",
       "      <td>3.209291</td>\n",
       "      <td>3.180449</td>\n",
       "      <td>3.201514</td>\n",
       "      <td>3.208421</td>\n",
       "      <td>-0.822909</td>\n",
       "      <td>2.602116</td>\n",
       "      <td>4.250910</td>\n",
       "      <td>1.386833</td>\n",
       "      <td>3.273919</td>\n",
       "      <td>3.242147</td>\n",
       "      <td>3.210934</td>\n",
       "      <td>-0.565663</td>\n",
       "      <td>-0.779288</td>\n",
       "      <td>-0.213978</td>\n",
       "      <td>-0.184687</td>\n",
       "      <td>-0.276358</td>\n",
       "      <td>3.410207</td>\n",
       "      <td>3.157878</td>\n",
       "      <td>1.631892</td>\n",
       "      <td>1.130228</td>\n",
       "      <td>0.126510</td>\n",
       "      <td>0.712661</td>\n",
       "      <td>1.793680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-04 00:00:00-04:00</th>\n",
       "      <td>3.218160</td>\n",
       "      <td>3.241187</td>\n",
       "      <td>3.253418</td>\n",
       "      <td>3.276763</td>\n",
       "      <td>-0.899730</td>\n",
       "      <td>2.891652</td>\n",
       "      <td>4.157658</td>\n",
       "      <td>1.725544</td>\n",
       "      <td>3.278061</td>\n",
       "      <td>3.252684</td>\n",
       "      <td>3.227547</td>\n",
       "      <td>-0.492262</td>\n",
       "      <td>0.669964</td>\n",
       "      <td>-0.237469</td>\n",
       "      <td>0.259177</td>\n",
       "      <td>-0.418674</td>\n",
       "      <td>3.335308</td>\n",
       "      <td>3.183268</td>\n",
       "      <td>1.609862</td>\n",
       "      <td>1.138204</td>\n",
       "      <td>0.793974</td>\n",
       "      <td>0.980959</td>\n",
       "      <td>-1.298515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-05 00:00:00-04:00</th>\n",
       "      <td>3.257335</td>\n",
       "      <td>3.238260</td>\n",
       "      <td>3.255410</td>\n",
       "      <td>3.226400</td>\n",
       "      <td>-0.930582</td>\n",
       "      <td>2.877746</td>\n",
       "      <td>3.289193</td>\n",
       "      <td>1.993551</td>\n",
       "      <td>3.276643</td>\n",
       "      <td>3.241505</td>\n",
       "      <td>3.207092</td>\n",
       "      <td>-0.603957</td>\n",
       "      <td>-0.298923</td>\n",
       "      <td>-0.259283</td>\n",
       "      <td>0.091324</td>\n",
       "      <td>-0.542271</td>\n",
       "      <td>3.243982</td>\n",
       "      <td>3.205782</td>\n",
       "      <td>1.198331</td>\n",
       "      <td>1.130600</td>\n",
       "      <td>-0.657657</td>\n",
       "      <td>0.642552</td>\n",
       "      <td>-3.660592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-06 00:00:00-04:00</th>\n",
       "      <td>3.157799</td>\n",
       "      <td>3.142275</td>\n",
       "      <td>3.091606</td>\n",
       "      <td>3.086269</td>\n",
       "      <td>-0.468886</td>\n",
       "      <td>2.259448</td>\n",
       "      <td>1.013217</td>\n",
       "      <td>2.076264</td>\n",
       "      <td>3.176074</td>\n",
       "      <td>3.206068</td>\n",
       "      <td>3.233580</td>\n",
       "      <td>0.139083</td>\n",
       "      <td>-1.651889</td>\n",
       "      <td>-0.349066</td>\n",
       "      <td>-0.324872</td>\n",
       "      <td>0.818854</td>\n",
       "      <td>3.493913</td>\n",
       "      <td>3.221622</td>\n",
       "      <td>0.635555</td>\n",
       "      <td>1.117429</td>\n",
       "      <td>-1.797509</td>\n",
       "      <td>-0.139058</td>\n",
       "      <td>0.624372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-07 00:00:00-04:00</th>\n",
       "      <td>3.052720</td>\n",
       "      <td>3.101417</td>\n",
       "      <td>3.087125</td>\n",
       "      <td>3.109296</td>\n",
       "      <td>-0.705789</td>\n",
       "      <td>1.841360</td>\n",
       "      <td>-0.283777</td>\n",
       "      <td>2.053386</td>\n",
       "      <td>3.138732</td>\n",
       "      <td>3.188941</td>\n",
       "      <td>3.235676</td>\n",
       "      <td>0.373475</td>\n",
       "      <td>-0.960629</td>\n",
       "      <td>-0.427710</td>\n",
       "      <td>-0.512739</td>\n",
       "      <td>0.615468</td>\n",
       "      <td>3.472452</td>\n",
       "      <td>3.230370</td>\n",
       "      <td>0.083267</td>\n",
       "      <td>1.127743</td>\n",
       "      <td>0.250294</td>\n",
       "      <td>-0.027520</td>\n",
       "      <td>-1.460009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-09 00:00:00-05:00</th>\n",
       "      <td>4.055263</td>\n",
       "      <td>4.058072</td>\n",
       "      <td>4.093601</td>\n",
       "      <td>4.100739</td>\n",
       "      <td>-0.993945</td>\n",
       "      <td>0.658100</td>\n",
       "      <td>-1.089671</td>\n",
       "      <td>1.055703</td>\n",
       "      <td>4.089064</td>\n",
       "      <td>4.054501</td>\n",
       "      <td>4.020381</td>\n",
       "      <td>-0.529700</td>\n",
       "      <td>1.062636</td>\n",
       "      <td>-0.719379</td>\n",
       "      <td>-0.648233</td>\n",
       "      <td>-0.572705</td>\n",
       "      <td>2.321402</td>\n",
       "      <td>4.075913</td>\n",
       "      <td>0.562165</td>\n",
       "      <td>1.173857</td>\n",
       "      <td>0.095342</td>\n",
       "      <td>0.248983</td>\n",
       "      <td>1.857415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-10 00:00:00-05:00</th>\n",
       "      <td>4.109843</td>\n",
       "      <td>4.159457</td>\n",
       "      <td>4.158491</td>\n",
       "      <td>4.188083</td>\n",
       "      <td>-0.866381</td>\n",
       "      <td>1.118552</td>\n",
       "      <td>0.332342</td>\n",
       "      <td>1.082984</td>\n",
       "      <td>4.062715</td>\n",
       "      <td>4.085021</td>\n",
       "      <td>4.104951</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>1.308142</td>\n",
       "      <td>-0.632940</td>\n",
       "      <td>0.400287</td>\n",
       "      <td>-0.818959</td>\n",
       "      <td>2.428566</td>\n",
       "      <td>4.077872</td>\n",
       "      <td>0.608439</td>\n",
       "      <td>1.182235</td>\n",
       "      <td>0.823429</td>\n",
       "      <td>1.524423</td>\n",
       "      <td>0.485936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-11 00:00:00-05:00</th>\n",
       "      <td>4.230397</td>\n",
       "      <td>4.240142</td>\n",
       "      <td>4.209845</td>\n",
       "      <td>4.211359</td>\n",
       "      <td>-0.802749</td>\n",
       "      <td>1.559655</td>\n",
       "      <td>1.419333</td>\n",
       "      <td>1.198760</td>\n",
       "      <td>4.093447</td>\n",
       "      <td>4.126876</td>\n",
       "      <td>4.157367</td>\n",
       "      <td>0.102924</td>\n",
       "      <td>0.986379</td>\n",
       "      <td>-0.464720</td>\n",
       "      <td>0.955108</td>\n",
       "      <td>-1.075370</td>\n",
       "      <td>2.600081</td>\n",
       "      <td>4.084783</td>\n",
       "      <td>0.628753</td>\n",
       "      <td>1.191381</td>\n",
       "      <td>0.185509</td>\n",
       "      <td>1.781973</td>\n",
       "      <td>0.998361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-12 00:00:00-05:00</th>\n",
       "      <td>4.224012</td>\n",
       "      <td>4.215354</td>\n",
       "      <td>4.263856</td>\n",
       "      <td>4.259410</td>\n",
       "      <td>-0.971731</td>\n",
       "      <td>2.081812</td>\n",
       "      <td>2.500980</td>\n",
       "      <td>1.402597</td>\n",
       "      <td>4.167225</td>\n",
       "      <td>4.178838</td>\n",
       "      <td>4.188574</td>\n",
       "      <td>-0.099700</td>\n",
       "      <td>1.098968</td>\n",
       "      <td>-0.308516</td>\n",
       "      <td>0.754199</td>\n",
       "      <td>-1.166083</td>\n",
       "      <td>2.524947</td>\n",
       "      <td>4.097269</td>\n",
       "      <td>0.666782</td>\n",
       "      <td>1.198489</td>\n",
       "      <td>0.424868</td>\n",
       "      <td>2.021079</td>\n",
       "      <td>0.463353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-16 00:00:00-05:00</th>\n",
       "      <td>4.326289</td>\n",
       "      <td>4.281662</td>\n",
       "      <td>4.301424</td>\n",
       "      <td>4.281934</td>\n",
       "      <td>-0.820409</td>\n",
       "      <td>2.557213</td>\n",
       "      <td>3.243974</td>\n",
       "      <td>1.666922</td>\n",
       "      <td>4.212710</td>\n",
       "      <td>4.217909</td>\n",
       "      <td>4.221537</td>\n",
       "      <td>-0.158681</td>\n",
       "      <td>0.921821</td>\n",
       "      <td>-0.103574</td>\n",
       "      <td>1.278765</td>\n",
       "      <td>-1.301808</td>\n",
       "      <td>2.543690</td>\n",
       "      <td>4.115000</td>\n",
       "      <td>0.752161</td>\n",
       "      <td>1.207421</td>\n",
       "      <td>0.174933</td>\n",
       "      <td>1.893469</td>\n",
       "      <td>-0.204983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>449 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Open      High       Low     Close    Volume   \n",
       "Date                                                                          \n",
       "2022-04-01 00:00:00-04:00  3.209291  3.180449  3.201514  3.208421 -0.822909  \\\n",
       "2022-04-04 00:00:00-04:00  3.218160  3.241187  3.253418  3.276763 -0.899730   \n",
       "2022-04-05 00:00:00-04:00  3.257335  3.238260  3.255410  3.226400 -0.930582   \n",
       "2022-04-06 00:00:00-04:00  3.157799  3.142275  3.091606  3.086269 -0.468886   \n",
       "2022-04-07 00:00:00-04:00  3.052720  3.101417  3.087125  3.109296 -0.705789   \n",
       "...                             ...       ...       ...       ...       ...   \n",
       "2024-01-09 00:00:00-05:00  4.055263  4.058072  4.093601  4.100739 -0.993945   \n",
       "2024-01-10 00:00:00-05:00  4.109843  4.159457  4.158491  4.188083 -0.866381   \n",
       "2024-01-11 00:00:00-05:00  4.230397  4.240142  4.209845  4.211359 -0.802749   \n",
       "2024-01-12 00:00:00-05:00  4.224012  4.215354  4.263856  4.259410 -0.971731   \n",
       "2024-01-16 00:00:00-05:00  4.326289  4.281662  4.301424  4.281934 -0.820409   \n",
       "\n",
       "                           MACD_12_26_9  MACDh_12_26_9  MACDs_12_26_9   \n",
       "Date                                                                    \n",
       "2022-04-01 00:00:00-04:00      2.602116       4.250910       1.386833  \\\n",
       "2022-04-04 00:00:00-04:00      2.891652       4.157658       1.725544   \n",
       "2022-04-05 00:00:00-04:00      2.877746       3.289193       1.993551   \n",
       "2022-04-06 00:00:00-04:00      2.259448       1.013217       2.076264   \n",
       "2022-04-07 00:00:00-04:00      1.841360      -0.283777       2.053386   \n",
       "...                                 ...            ...            ...   \n",
       "2024-01-09 00:00:00-05:00      0.658100      -1.089671       1.055703   \n",
       "2024-01-10 00:00:00-05:00      1.118552       0.332342       1.082984   \n",
       "2024-01-11 00:00:00-05:00      1.559655       1.419333       1.198760   \n",
       "2024-01-12 00:00:00-05:00      2.081812       2.500980       1.402597   \n",
       "2024-01-16 00:00:00-05:00      2.557213       3.243974       1.666922   \n",
       "\n",
       "                           BBL_5_2.0  BBM_5_2.0  BBU_5_2.0  BBB_5_2.0   \n",
       "Date                                                                    \n",
       "2022-04-01 00:00:00-04:00   3.273919   3.242147   3.210934  -0.565663  \\\n",
       "2022-04-04 00:00:00-04:00   3.278061   3.252684   3.227547  -0.492262   \n",
       "2022-04-05 00:00:00-04:00   3.276643   3.241505   3.207092  -0.603957   \n",
       "2022-04-06 00:00:00-04:00   3.176074   3.206068   3.233580   0.139083   \n",
       "2022-04-07 00:00:00-04:00   3.138732   3.188941   3.235676   0.373475   \n",
       "...                              ...        ...        ...        ...   \n",
       "2024-01-09 00:00:00-05:00   4.089064   4.054501   4.020381  -0.529700   \n",
       "2024-01-10 00:00:00-05:00   4.062715   4.085021   4.104951   0.002098   \n",
       "2024-01-11 00:00:00-05:00   4.093447   4.126876   4.157367   0.102924   \n",
       "2024-01-12 00:00:00-05:00   4.167225   4.178838   4.188574  -0.099700   \n",
       "2024-01-16 00:00:00-05:00   4.212710   4.217909   4.221537  -0.158681   \n",
       "\n",
       "                           BBP_5_2.0    ADX_14    DMP_14    DMN_14   ATRr_14   \n",
       "Date                                                                           \n",
       "2022-04-01 00:00:00-04:00  -0.779288 -0.213978 -0.184687 -0.276358  3.410207  \\\n",
       "2022-04-04 00:00:00-04:00   0.669964 -0.237469  0.259177 -0.418674  3.335308   \n",
       "2022-04-05 00:00:00-04:00  -0.298923 -0.259283  0.091324 -0.542271  3.243982   \n",
       "2022-04-06 00:00:00-04:00  -1.651889 -0.349066 -0.324872  0.818854  3.493913   \n",
       "2022-04-07 00:00:00-04:00  -0.960629 -0.427710 -0.512739  0.615468  3.472452   \n",
       "...                              ...       ...       ...       ...       ...   \n",
       "2024-01-09 00:00:00-05:00   1.062636 -0.719379 -0.648233 -0.572705  2.321402   \n",
       "2024-01-10 00:00:00-05:00   1.308142 -0.632940  0.400287 -0.818959  2.428566   \n",
       "2024-01-11 00:00:00-05:00   0.986379 -0.464720  0.955108 -1.075370  2.600081   \n",
       "2024-01-12 00:00:00-05:00   1.098968 -0.308516  0.754199 -1.166083  2.524947   \n",
       "2024-01-16 00:00:00-05:00   0.921821 -0.103574  1.278765 -1.301808  2.543690   \n",
       "\n",
       "                           T3_10_0.7    MFI_14       OBV  LOGRET_1     ZS_30   \n",
       "Date                                                                           \n",
       "2022-04-01 00:00:00-04:00   3.157878  1.631892  1.130228  0.126510  0.712661  \\\n",
       "2022-04-04 00:00:00-04:00   3.183268  1.609862  1.138204  0.793974  0.980959   \n",
       "2022-04-05 00:00:00-04:00   3.205782  1.198331  1.130600 -0.657657  0.642552   \n",
       "2022-04-06 00:00:00-04:00   3.221622  0.635555  1.117429 -1.797509 -0.139058   \n",
       "2022-04-07 00:00:00-04:00   3.230370  0.083267  1.127743  0.250294 -0.027520   \n",
       "...                              ...       ...       ...       ...       ...   \n",
       "2024-01-09 00:00:00-05:00   4.075913  0.562165  1.173857  0.095342  0.248983   \n",
       "2024-01-10 00:00:00-05:00   4.077872  0.608439  1.182235  0.823429  1.524423   \n",
       "2024-01-11 00:00:00-05:00   4.084783  0.628753  1.191381  0.185509  1.781973   \n",
       "2024-01-12 00:00:00-05:00   4.097269  0.666782  1.198489  0.424868  2.021079   \n",
       "2024-01-16 00:00:00-05:00   4.115000  0.752161  1.207421  0.174933  1.893469   \n",
       "\n",
       "                             Target  \n",
       "Date                                 \n",
       "2022-04-01 00:00:00-04:00  1.793680  \n",
       "2022-04-04 00:00:00-04:00 -1.298515  \n",
       "2022-04-05 00:00:00-04:00 -3.660592  \n",
       "2022-04-06 00:00:00-04:00  0.624372  \n",
       "2022-04-07 00:00:00-04:00 -1.460009  \n",
       "...                             ...  \n",
       "2024-01-09 00:00:00-05:00  1.857415  \n",
       "2024-01-10 00:00:00-05:00  0.485936  \n",
       "2024-01-11 00:00:00-05:00  0.998361  \n",
       "2024-01-12 00:00:00-05:00  0.463353  \n",
       "2024-01-16 00:00:00-05:00 -0.204983  \n",
       "\n",
       "[449 rows x 23 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "\n",
    "sequence_size = 50\n",
    "batch_size = 256\n",
    "features_size = len(train_df.drop(['Target'], axis=1).columns)\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df=pd.DataFrame(), label='', sequence_size=30):\n",
    "        self.df = df\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) - sequence_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        seq = Tensor(np.array(self.df.drop(self.label, axis=1).iloc[idx:idx+sequence_size, :], dtype=float))\n",
    "        label = Tensor(np.array(self.df[[self.label]].iloc[idx+sequence_size, :], dtype=float))\n",
    "\n",
    "        return (seq, label)\n",
    "\n",
    "train_data = TensorDataset(Tensor(np.array(train_df.drop(['Target'], axis=1))), Tensor(np.array(train_df['Target'])))\n",
    "test_data = TensorDataset(Tensor(np.array(test_df.drop(['Target'], axis=1))), Tensor(np.array(test_df['Target'])))\n",
    "\n",
    "# train_loader = DataLoader(train_data)\n",
    "# test_loader = DataLoader(test_data)\n",
    "\n",
    "# train_loader = DataLoader(PandasDataset(train_df, labels=['Target']))\n",
    "# test_loader = DataLoader(PandasDataset(test_df, labels=['Target']))\n",
    "\n",
    "train_loader = DataLoader(SequenceDataset(train_df, label='Target', sequence_size=sequence_size), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(SequenceDataset(test_df, label='Target', sequence_size=sequence_size), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 22\n"
     ]
    }
   ],
   "source": [
    "print(batch_size, features_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " [tensor([[[ 2.7963,  2.7927,  2.7675,  ...,  1.0879,  0.0525, -0.1083],\n",
       "           [ 2.6635,  2.7555,  2.6622,  ...,  1.1023,  0.3290,  0.0795],\n",
       "           [ 2.7359,  2.7409,  2.7471,  ...,  1.0931, -0.8307, -0.2239],\n",
       "           ...,\n",
       "           [ 2.8511,  2.8586,  2.8619,  ...,  1.1114,  0.2886,  0.9069],\n",
       "           [ 2.9564,  2.9409,  2.9783,  ...,  1.1195,  1.0872,  1.2329],\n",
       "           [ 2.9895,  2.9580,  2.9730,  ...,  1.1129, -0.3922,  0.9715]],\n",
       "  \n",
       "          [[ 2.7250,  2.7198,  2.6760,  ...,  1.0864, -1.8141, -1.5917],\n",
       "           [ 2.7451,  2.7367,  2.6978,  ...,  1.0993,  0.8244, -1.2689],\n",
       "           [ 2.6711,  2.7076,  2.6260,  ...,  1.0832, -1.6319, -1.6474],\n",
       "           ...,\n",
       "           [ 2.6055,  2.5867,  2.5586,  ...,  1.0835, -0.4976, -0.6799],\n",
       "           [ 2.5787,  2.5730,  2.5634,  ...,  1.0917,  0.9246, -0.1646],\n",
       "           [ 2.6073,  2.6360,  2.6286,  ...,  1.0992,  0.4516,  0.1229]],\n",
       "  \n",
       "          [[ 2.2907,  2.2759,  2.2884,  ...,  0.9743, -0.7947, -0.8578],\n",
       "           [ 2.3011,  2.2860,  2.2406,  ...,  0.9643, -0.8523, -1.2249],\n",
       "           [ 2.2375,  2.2316,  2.1495,  ...,  0.9517, -1.7371, -1.8870],\n",
       "           ...,\n",
       "           [ 2.2082,  2.2388,  2.2371,  ...,  0.9510,  0.4133, -1.5730],\n",
       "           [ 2.2244,  2.2397,  2.2486,  ...,  0.9599,  0.3145, -1.3431],\n",
       "           [ 2.2682,  2.2967,  2.2960,  ...,  0.9693,  1.3592, -0.7686]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 2.7836,  2.8038,  2.7750,  ...,  1.1021, -0.4892, -1.1672],\n",
       "           [ 2.7250,  2.7198,  2.6760,  ...,  1.0864, -1.8141, -1.5917],\n",
       "           [ 2.7451,  2.7367,  2.6978,  ...,  1.0993,  0.8244, -1.2689],\n",
       "           ...,\n",
       "           [ 2.5557,  2.5810,  2.5770,  ...,  1.0904,  0.4438, -0.5047],\n",
       "           [ 2.6055,  2.5867,  2.5586,  ...,  1.0835, -0.4976, -0.6799],\n",
       "           [ 2.5787,  2.5730,  2.5634,  ...,  1.0917,  0.9246, -0.1646]],\n",
       "  \n",
       "          [[ 2.7359,  2.7409,  2.7471,  ...,  1.0931, -0.8307, -0.2239],\n",
       "           [ 2.7575,  2.7498,  2.7323,  ...,  1.0857, -0.2645, -0.3058],\n",
       "           [ 2.6906,  2.7369,  2.7163,  ...,  1.0933,  0.6095, -0.0070],\n",
       "           ...,\n",
       "           [ 2.9895,  2.9580,  2.9730,  ...,  1.1129, -0.3922,  0.9715],\n",
       "           [ 2.9602,  2.9665,  2.9783,  ...,  1.1203,  0.7524,  1.1443],\n",
       "           [ 2.9913,  2.9943,  3.0179,  ...,  1.1262,  0.2082,  1.1008]],\n",
       "  \n",
       "          [[ 3.4367,  3.4297,  3.4716,  ...,  1.0241,  0.2302,  0.3127],\n",
       "           [ 3.4498,  3.4710,  3.4849,  ...,  1.0315,  0.1782,  0.3748],\n",
       "           [ 3.4946,  3.4971,  3.4944,  ...,  1.0395,  0.6804,  0.6654],\n",
       "           ...,\n",
       "           [ 3.4061,  3.4108,  3.4354,  ...,  1.0298, -0.1570, -1.3098],\n",
       "           [ 3.4028,  3.3792,  3.3901,  ...,  1.0228, -0.5624, -1.4584],\n",
       "           [ 3.3272,  3.3361,  3.3312,  ...,  1.0147, -0.1020, -1.3942]]]),\n",
       "  tensor([[ 5.3441e-01],\n",
       "          [-1.6916e+00],\n",
       "          [ 3.0187e-01],\n",
       "          [-1.0255e+00],\n",
       "          [-5.5327e-01],\n",
       "          [-8.4656e-01],\n",
       "          [-2.2536e+00],\n",
       "          [-1.9034e-01],\n",
       "          [-1.2766e+00],\n",
       "          [-1.0497e+00],\n",
       "          [ 1.7157e+00],\n",
       "          [-1.6750e+00],\n",
       "          [ 7.5293e-01],\n",
       "          [-5.9082e-01],\n",
       "          [ 6.6852e+00],\n",
       "          [ 7.8557e-01],\n",
       "          [ 1.2759e+00],\n",
       "          [-5.4424e-01],\n",
       "          [ 1.0707e+00],\n",
       "          [-5.0468e-01],\n",
       "          [-4.0981e+00],\n",
       "          [ 1.2813e+00],\n",
       "          [ 2.4300e+00],\n",
       "          [ 1.7063e+00],\n",
       "          [ 3.2347e-01],\n",
       "          [-7.5789e-01],\n",
       "          [ 1.2311e+00],\n",
       "          [ 2.1013e+00],\n",
       "          [ 9.4071e-01],\n",
       "          [ 7.3677e-01],\n",
       "          [ 1.9722e+00],\n",
       "          [-2.6623e+00],\n",
       "          [-1.1612e+00],\n",
       "          [ 7.8787e-01],\n",
       "          [ 3.7717e-01],\n",
       "          [-1.8432e+00],\n",
       "          [ 3.3181e-01],\n",
       "          [ 1.9711e+00],\n",
       "          [-1.5984e+00],\n",
       "          [ 4.0537e+00],\n",
       "          [ 2.0522e+00],\n",
       "          [ 2.8889e+00],\n",
       "          [ 8.2812e-01],\n",
       "          [-1.3963e+00],\n",
       "          [-1.4783e+00],\n",
       "          [-1.2698e+00],\n",
       "          [ 1.7773e+00],\n",
       "          [-5.4978e+00],\n",
       "          [-1.1578e+00],\n",
       "          [-1.0974e+00],\n",
       "          [ 1.4193e-01],\n",
       "          [-1.2629e+00],\n",
       "          [-1.2623e-01],\n",
       "          [-3.5128e-01],\n",
       "          [-1.9756e+00],\n",
       "          [ 4.6884e+00],\n",
       "          [ 7.6171e-01],\n",
       "          [-2.3514e-01],\n",
       "          [ 1.2620e+00],\n",
       "          [ 2.3336e-01],\n",
       "          [-2.7119e+00],\n",
       "          [ 1.8168e+00],\n",
       "          [ 2.9358e-01],\n",
       "          [ 5.3815e-01],\n",
       "          [-1.3179e+00],\n",
       "          [-2.1498e+00],\n",
       "          [ 1.2502e-01],\n",
       "          [-2.0872e+00],\n",
       "          [-3.9477e-01],\n",
       "          [ 2.3543e+00],\n",
       "          [ 2.2670e-01],\n",
       "          [-9.8892e-01],\n",
       "          [ 1.9161e+00],\n",
       "          [ 7.2435e+00],\n",
       "          [-1.7638e-01],\n",
       "          [-2.1784e+00],\n",
       "          [-8.5142e-01],\n",
       "          [-1.4436e+00],\n",
       "          [ 9.4516e-01],\n",
       "          [ 9.2961e-01],\n",
       "          [ 4.7337e-02],\n",
       "          [ 8.8422e-01],\n",
       "          [ 9.7363e-01],\n",
       "          [-2.0498e-01],\n",
       "          [-4.9088e-02],\n",
       "          [ 1.2783e+00],\n",
       "          [-9.7243e-01],\n",
       "          [ 1.2958e-01],\n",
       "          [ 1.0480e+00],\n",
       "          [ 1.4962e+00],\n",
       "          [-1.2299e+00],\n",
       "          [ 1.5082e-01],\n",
       "          [-4.3798e-01],\n",
       "          [-2.6134e+00],\n",
       "          [-1.7006e+00],\n",
       "          [-2.3122e+00],\n",
       "          [-1.5748e-01],\n",
       "          [-7.0729e-01],\n",
       "          [-2.4249e+00],\n",
       "          [-7.8295e-01],\n",
       "          [ 1.0877e+00],\n",
       "          [-1.1116e-01],\n",
       "          [-1.1769e+00],\n",
       "          [ 2.2977e+00],\n",
       "          [ 1.3117e+00],\n",
       "          [ 4.0600e-02],\n",
       "          [-7.2405e-01],\n",
       "          [-1.1716e+00],\n",
       "          [ 8.4793e-01],\n",
       "          [-6.4382e-01],\n",
       "          [-1.2503e+00],\n",
       "          [ 2.1188e+00],\n",
       "          [-1.7428e-02],\n",
       "          [ 1.7037e+00],\n",
       "          [ 1.2597e+00],\n",
       "          [ 2.7841e-01],\n",
       "          [ 2.0767e+00],\n",
       "          [ 2.1386e+00],\n",
       "          [ 2.2292e-01],\n",
       "          [ 6.1624e+00],\n",
       "          [ 1.2862e+00],\n",
       "          [ 7.1084e-01],\n",
       "          [-2.6082e-01],\n",
       "          [-2.0304e+00],\n",
       "          [-4.3743e+00],\n",
       "          [ 3.8258e-01],\n",
       "          [ 5.6145e-01],\n",
       "          [-2.2260e-01],\n",
       "          [ 2.5533e+00],\n",
       "          [ 2.1722e-01],\n",
       "          [ 1.8872e+00],\n",
       "          [-1.7349e+00],\n",
       "          [-2.6090e-01],\n",
       "          [ 2.0824e-01],\n",
       "          [-9.6710e-01],\n",
       "          [-2.9638e+00],\n",
       "          [-7.0443e-01],\n",
       "          [-6.9108e-01],\n",
       "          [ 1.7830e+00],\n",
       "          [ 1.7009e+00],\n",
       "          [ 1.5837e-02],\n",
       "          [ 6.7274e-01],\n",
       "          [ 3.4409e-01],\n",
       "          [ 3.3663e+00],\n",
       "          [ 1.8574e+00],\n",
       "          [-2.7573e-01],\n",
       "          [ 5.1789e-01],\n",
       "          [ 3.3812e+00],\n",
       "          [-1.0007e-01],\n",
       "          [ 6.4512e-02],\n",
       "          [-1.4889e-01],\n",
       "          [-2.5898e-01],\n",
       "          [ 2.7836e+00],\n",
       "          [-1.7328e+00],\n",
       "          [-2.2500e+00],\n",
       "          [ 1.9288e-01],\n",
       "          [-7.4881e-01],\n",
       "          [ 1.6662e-01],\n",
       "          [ 1.4079e+00],\n",
       "          [ 1.1694e+00],\n",
       "          [-1.0668e+00],\n",
       "          [-3.1749e+00],\n",
       "          [ 3.2028e+00],\n",
       "          [-5.7041e-01],\n",
       "          [ 2.7056e+00],\n",
       "          [ 1.4550e+00],\n",
       "          [-4.1609e-01],\n",
       "          [-8.0884e-01],\n",
       "          [-6.7275e-01],\n",
       "          [ 1.6386e+00],\n",
       "          [ 7.0633e-01],\n",
       "          [-8.4696e-01],\n",
       "          [ 1.4982e+00],\n",
       "          [ 2.3717e-01],\n",
       "          [ 2.2636e+00],\n",
       "          [-7.1776e-01],\n",
       "          [-5.8766e-01],\n",
       "          [-1.0986e+00],\n",
       "          [ 2.4737e+00],\n",
       "          [ 4.8594e-01],\n",
       "          [-2.6970e+00],\n",
       "          [ 4.0838e-01],\n",
       "          [-3.1918e+00],\n",
       "          [-1.3955e-01],\n",
       "          [ 1.2962e+00],\n",
       "          [-4.0924e-01],\n",
       "          [ 4.2022e+00],\n",
       "          [-2.6579e+00],\n",
       "          [ 1.1785e+00],\n",
       "          [ 1.6101e-01],\n",
       "          [-8.0033e-01],\n",
       "          [-5.3458e-01],\n",
       "          [-2.5649e-01],\n",
       "          [ 1.0803e+00],\n",
       "          [ 4.3885e-01],\n",
       "          [-1.6454e+00],\n",
       "          [-1.7437e-01],\n",
       "          [-1.7059e+00],\n",
       "          [ 1.8235e-01],\n",
       "          [-2.3621e+00],\n",
       "          [ 1.2857e-01],\n",
       "          [-2.3821e-01],\n",
       "          [-3.8657e-01],\n",
       "          [-9.6214e-01],\n",
       "          [-3.6349e-02],\n",
       "          [ 2.7459e-01],\n",
       "          [-1.2267e+00],\n",
       "          [-2.2668e+00],\n",
       "          [-3.1021e-01],\n",
       "          [ 2.4897e+00],\n",
       "          [ 9.8243e-01],\n",
       "          [-8.9221e-01],\n",
       "          [-7.9929e-01],\n",
       "          [-3.5368e+00],\n",
       "          [ 1.7583e+00],\n",
       "          [ 3.1897e+00],\n",
       "          [-1.9369e+00],\n",
       "          [ 2.2740e+00],\n",
       "          [-3.7637e+00],\n",
       "          [ 1.4395e+00],\n",
       "          [ 1.9184e+00],\n",
       "          [ 1.6646e+00],\n",
       "          [ 1.9653e+00],\n",
       "          [ 3.1329e-01],\n",
       "          [ 3.6742e-01],\n",
       "          [-1.0357e+00],\n",
       "          [-8.9885e-02],\n",
       "          [-2.5767e+00],\n",
       "          [-2.0684e-02],\n",
       "          [ 6.5016e-01],\n",
       "          [ 5.8136e-01],\n",
       "          [-1.4934e+00],\n",
       "          [ 3.9246e+00],\n",
       "          [ 8.2268e+00],\n",
       "          [ 1.9935e+00],\n",
       "          [-1.4339e+00],\n",
       "          [ 2.0252e-01],\n",
       "          [-2.6737e-03],\n",
       "          [ 3.5744e+00],\n",
       "          [ 1.0940e+00],\n",
       "          [ 9.7906e-01],\n",
       "          [-5.9454e-01],\n",
       "          [-1.2460e-01],\n",
       "          [-8.1125e-01],\n",
       "          [-1.0060e+00],\n",
       "          [-1.3854e+00],\n",
       "          [-1.1660e+00],\n",
       "          [-3.0597e-01],\n",
       "          [ 7.4057e-01],\n",
       "          [-1.6576e+00],\n",
       "          [ 5.8556e-01],\n",
       "          [-5.0853e+00],\n",
       "          [ 1.7465e+00],\n",
       "          [ 9.7990e-01],\n",
       "          [-2.6360e-01],\n",
       "          [ 1.8018e-01]])])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(test_loader))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddenSize = 128\n",
    "\n",
    "class extract_tensor(nn.Module):\n",
    "    def forward(self,x):\n",
    "        # Output shape (batch, features, hidden)\n",
    "        tensor, _ = x\n",
    "        # Reshape shape (batch, hidden)\n",
    "        return tensor[:, -1, :]\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.GRU(features_size, hiddenSize, num_layers=1, batch_first=True),\n",
    "    nn.Sequential(\n",
    "      extract_tensor(),\n",
    "      nn.Linear(hiddenSize, int(hiddenSize/2)),\n",
    "      nn.Linear(int(hiddenSize/2), 1),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "loss_function = nn.GaussianNLLLoss()\n",
    "# loss_function = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=1e-3)\n",
    "# optimizer = optim.RAdam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=0, loss=81.5]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=1, loss=82]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=2, loss=82.8]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=3, loss=80.9]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=4, loss=79.5]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=5, loss=79.7]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=6, loss=80.4]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=7, loss=79.7]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=8, loss=79.8]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=9, loss=79.8]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=10, loss=80.2]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=11, loss=79.7]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=12, loss=79.6]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=13, loss=78.9]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=14, loss=80]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=15, loss=78.3]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=16, loss=79]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=17, loss=77.6]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=18, loss=76.7]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=19, loss=76.9]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=20, loss=76.6]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=21, loss=75.6]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=22, loss=76.7]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=23, loss=75.2]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=24, loss=77.5]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=25, loss=75.5]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=26, loss=74.4]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=27, loss=72.7]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=28, loss=72.2]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=29, loss=72]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=30, loss=71.7]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=31, loss=71.4]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=32, loss=70.8]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=33, loss=70.6]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=34, loss=70]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=35, loss=69.5]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=36, loss=70.5]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=37, loss=67.7]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=38, loss=66.6]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=39, loss=66]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=40, loss=66]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=41, loss=64.8]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=42, loss=65.2]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=43, loss=62.9]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=44, loss=61.5]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=45, loss=62.9]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=46, loss=61.5]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=47, loss=59.3]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=48, loss=58.7]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=49, loss=58.3]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=50, loss=57.8]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=51, loss=57.2]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=52, loss=55.7]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=53, loss=55.8]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=54, loss=54.7]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=55, loss=53.2]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=56, loss=52.7]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=57, loss=52.3]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=58, loss=53]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=59, loss=51.9]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=60, loss=49.6]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=61, loss=48.8]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=62, loss=49.5]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=63, loss=48.6]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=64, loss=46.7]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=65, loss=45.5]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=66, loss=45]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=67, loss=44.7]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=68, loss=43.1]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=69, loss=42.6]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=70, loss=41.8]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=71, loss=41.3]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=72, loss=40.7]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=73, loss=40.8]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=74, loss=38.8]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=75, loss=39.6]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=76, loss=38.3]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=77, loss=36.5]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=78, loss=35.5]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=79, loss=35.2]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=80, loss=34]  \n",
      "100%|██████████| 36/36 [00:12<00:00,  2.91it/s, epoch=81, loss=34]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=82, loss=32.8]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=83, loss=32.7]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=84, loss=32.2]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=85, loss=31.2]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=86, loss=30.7]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=87, loss=29.3]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=88, loss=30]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=89, loss=28.8]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=90, loss=29.2]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=91, loss=28.1]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=92, loss=28.1]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=93, loss=26.2]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=94, loss=26.6]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=95, loss=25.9]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=96, loss=24.3]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=97, loss=27]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=98, loss=26.1]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=99, loss=23.2]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=100, loss=23.8]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=101, loss=22.4]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=102, loss=21.9]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=103, loss=21.9]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=104, loss=21.4]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=105, loss=22.4]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=106, loss=21.3]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=107, loss=20.5]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=108, loss=19.9]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=109, loss=20.2]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=110, loss=19.5]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=111, loss=18.9]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=112, loss=18.3]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=113, loss=17.8]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=114, loss=17.4]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=115, loss=18.4]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=116, loss=16.9]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=117, loss=16.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=118, loss=16.2]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=119, loss=15.7]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=120, loss=16]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=121, loss=15.6]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=122, loss=14.3]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=123, loss=14.7]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=124, loss=14.9]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=125, loss=16.2]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=126, loss=14]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=127, loss=13.7]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=128, loss=13.4]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=129, loss=13.7]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=130, loss=12.6]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=131, loss=12.6]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=132, loss=12.2]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=133, loss=12.7]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=134, loss=12]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=135, loss=11.6]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=136, loss=11.9]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=137, loss=11.4]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=138, loss=11.2]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=139, loss=11]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=140, loss=10.9]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=141, loss=10.9]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=142, loss=11]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=143, loss=9.98]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=144, loss=9.83]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=145, loss=9.7] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=146, loss=9.31]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=147, loss=9.76]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=148, loss=8.89]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=149, loss=9.12]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=150, loss=9.05]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=151, loss=8.94]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=152, loss=8.59]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=153, loss=8.94]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=154, loss=8.48]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=155, loss=8.17]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=156, loss=7.77]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=157, loss=8.03]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=158, loss=8.12]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=159, loss=8.85]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=160, loss=7.14]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=161, loss=7.34]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=162, loss=8.13]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=163, loss=7.7] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=164, loss=6.78]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=165, loss=6.7] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=166, loss=6.99]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=167, loss=6.24]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=168, loss=6.58]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=169, loss=6.06]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=170, loss=6.12]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=171, loss=6.42]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=172, loss=6.66]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=173, loss=6.81]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=174, loss=6.03]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=175, loss=5.33]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=176, loss=5.89]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=177, loss=5.93]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=178, loss=6.41]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=179, loss=5.12]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=180, loss=5.11]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=181, loss=5.09]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=182, loss=6.06]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=183, loss=5.19]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=184, loss=5.39]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=185, loss=5.19]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=186, loss=4.73]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=187, loss=4.95]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=188, loss=6.3] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=189, loss=4.41]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=190, loss=4.58]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=191, loss=5.21]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=192, loss=4.35]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=193, loss=4.4] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=194, loss=4.06]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=195, loss=4.05]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=196, loss=4]   \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=197, loss=4.48]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=198, loss=4.82]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=199, loss=5.01]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=200, loss=3.95]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=201, loss=3.76]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=202, loss=3.7] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=203, loss=4.4] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=204, loss=3.45]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=205, loss=3.21] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=206, loss=3.76]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=207, loss=3.4]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=208, loss=3.33]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=209, loss=3.94]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=210, loss=3.72]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=211, loss=3.81]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=212, loss=3.28] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=213, loss=3.25]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=214, loss=3.56]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=215, loss=2.91] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=216, loss=3.48]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=217, loss=3.06]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=218, loss=2.98]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=219, loss=3.37] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=220, loss=3.11]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=221, loss=3.27]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=222, loss=2.66] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=223, loss=2.89]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=224, loss=2.92] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=225, loss=2.8] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=226, loss=2.5]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=227, loss=2.84] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=228, loss=3.74]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=229, loss=2.88]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=230, loss=2.78]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=231, loss=2.26] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=232, loss=2.67] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=233, loss=2.51] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=234, loss=2.35] \n",
      "100%|██████████| 36/36 [00:12<00:00,  2.90it/s, epoch=235, loss=2.88]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=236, loss=2.62] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=237, loss=2.61] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=238, loss=2.13] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=239, loss=2.08] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=240, loss=2.55] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=241, loss=2.52]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=242, loss=2.41] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=243, loss=2.17] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=244, loss=2.35] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=245, loss=2.2]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=246, loss=2]    \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=247, loss=2.76]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=248, loss=1.91] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=249, loss=2.47] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=250, loss=1.93] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=251, loss=2.48] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=252, loss=2.72]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=253, loss=1.91] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=254, loss=2.06] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=255, loss=1.83] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=256, loss=2]    \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=257, loss=2.31] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=258, loss=2.34] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=259, loss=1.69] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=260, loss=2.13] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=261, loss=2.13] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=262, loss=1.95] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=263, loss=1.96] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=264, loss=1.89] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=265, loss=1.91] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=266, loss=1.7]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=267, loss=2.31]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=268, loss=2.11] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=269, loss=2.85]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=270, loss=1.4]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=271, loss=2.02] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=272, loss=1.54] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=273, loss=1.83] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=274, loss=1.74] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=275, loss=1.8]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=276, loss=1.76] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=277, loss=1.72] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=278, loss=1.48] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=279, loss=1.67] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=280, loss=1.72] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=281, loss=1.99] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=282, loss=2.33]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=283, loss=1.41] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=284, loss=1.5]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=285, loss=1.75] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=286, loss=1.34] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=287, loss=1.67] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=288, loss=1.3]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=289, loss=2.56]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=290, loss=1.81] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=291, loss=1.1]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=292, loss=1.29] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=293, loss=1.78] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=294, loss=1.53] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=295, loss=1.44] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=296, loss=1.18] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=297, loss=1.88] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=298, loss=2.74]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=299, loss=1.7]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=300, loss=1.32] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=301, loss=1.57] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=302, loss=1.04] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=303, loss=1.35] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=304, loss=1.34] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=305, loss=1.6]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=306, loss=1.21] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=307, loss=1.28] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=308, loss=1.65] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=309, loss=1.35] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=310, loss=1.37] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=311, loss=1.14] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=312, loss=1.42] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=313, loss=1.41] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=314, loss=1.49] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=315, loss=1.18] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=316, loss=1.42] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=317, loss=1.19] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=318, loss=1.32] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=319, loss=1.71] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=320, loss=1.24] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=321, loss=0.946]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=322, loss=1.51] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=323, loss=1.31] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=324, loss=1.2]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=325, loss=1.49] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=326, loss=1.01] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=327, loss=1.17] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=328, loss=1.28] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=329, loss=1.15] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=330, loss=1.71] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=331, loss=1.65] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=332, loss=1.05] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=333, loss=0.758]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=334, loss=0.88] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=335, loss=1.96] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=336, loss=1.01] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=337, loss=1.47] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=338, loss=0.89] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=339, loss=1.13] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=340, loss=0.993]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=341, loss=1.44] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=342, loss=1.03] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=343, loss=1.28] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=344, loss=1.12] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=345, loss=1.53] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=346, loss=1.04] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=347, loss=1.23] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=348, loss=1.28] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=349, loss=1.19] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=350, loss=0.932]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=351, loss=1.26] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=352, loss=0.926]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=353, loss=1.29] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=354, loss=0.952]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=355, loss=0.885]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=356, loss=0.972]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=357, loss=1.58] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=358, loss=1.04] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=359, loss=0.857]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=360, loss=0.923]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=361, loss=1.25] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=362, loss=1.19] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=363, loss=1.13] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=364, loss=1.32] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=365, loss=0.819]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=366, loss=1.13] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=367, loss=1.28] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=368, loss=0.867]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=369, loss=0.898]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=370, loss=1.09] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=371, loss=1.06] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=372, loss=0.932]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=373, loss=0.963]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=374, loss=1.06] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=375, loss=1.38] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=376, loss=1.06] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=377, loss=1.1]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=378, loss=0.807]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=379, loss=0.858]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=380, loss=0.9]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=381, loss=1.26] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=382, loss=0.998]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=383, loss=0.967]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=384, loss=1.84] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=385, loss=0.973]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=386, loss=0.662]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=387, loss=0.917]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=388, loss=0.732]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=389, loss=0.818]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=390, loss=1.53] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=391, loss=1.06] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=392, loss=0.792]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=393, loss=0.931]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=394, loss=1]    \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=395, loss=0.821]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=396, loss=1.2]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=397, loss=0.951]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=398, loss=0.707]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=399, loss=0.873]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=400, loss=0.81] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=401, loss=0.978]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=402, loss=1.29] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=403, loss=1.19] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=404, loss=2.49] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=405, loss=1.44] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=406, loss=0.802]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=407, loss=0.479]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=408, loss=0.505]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=409, loss=0.667]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=410, loss=0.72] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=411, loss=0.856]\n",
      "100%|██████████| 36/36 [00:12<00:00,  2.85it/s, epoch=412, loss=1.08] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=413, loss=1.03] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=414, loss=0.798]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=415, loss=0.713]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=416, loss=1.02] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=417, loss=0.969]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=418, loss=0.78] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=419, loss=0.789]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=420, loss=0.95] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=421, loss=1.23] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=422, loss=1.05] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=423, loss=0.611]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=424, loss=0.813]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=425, loss=0.806]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=426, loss=1.65] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=427, loss=0.694]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=428, loss=0.637]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=429, loss=0.604]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=430, loss=0.778]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=431, loss=1.1]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=432, loss=0.69] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=433, loss=1.4]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=434, loss=0.657]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=435, loss=1.07] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=436, loss=0.882]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=437, loss=0.612]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=438, loss=0.696]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=439, loss=0.714]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=440, loss=0.776]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=441, loss=1.04] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=442, loss=0.89] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=443, loss=1.03] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=444, loss=0.8]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=445, loss=0.723]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=446, loss=0.718]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=447, loss=0.771]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=448, loss=0.726]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=449, loss=1.04] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=450, loss=0.592]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=451, loss=0.7]  \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=452, loss=0.921]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=453, loss=0.858]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=454, loss=0.751]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=455, loss=0.65] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=456, loss=0.525]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=457, loss=0.906]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=458, loss=0.887]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=459, loss=0.719]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=460, loss=0.891]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=461, loss=1.51] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=462, loss=1.03] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=463, loss=0.766]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=464, loss=0.645]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=465, loss=0.512]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=466, loss=0.689]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=467, loss=0.71] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=468, loss=0.78] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=469, loss=0.692]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=470, loss=1.01] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=471, loss=0.748]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=472, loss=0.662]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=473, loss=1.33] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=474, loss=0.598]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=475, loss=0.706]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=476, loss=0.773]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=477, loss=0.489]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=478, loss=0.946]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=479, loss=0.803]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=480, loss=0.567]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=481, loss=0.738]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=482, loss=0.806]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=483, loss=0.684]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=484, loss=0.925]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=485, loss=0.807]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=486, loss=0.623]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=487, loss=0.749]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=488, loss=0.489]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=489, loss=0.596]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=490, loss=1.22] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=491, loss=0.747]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=492, loss=0.599]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=493, loss=0.74] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=494, loss=0.618]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=495, loss=0.712]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=496, loss=0.697]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=497, loss=0.781]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=498, loss=0.924]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=499, loss=0.732]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=500, loss=0.61] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=501, loss=0.458]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=502, loss=0.61] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=503, loss=0.664]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=504, loss=0.756]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=505, loss=0.808]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=506, loss=0.665]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=507, loss=0.674]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=508, loss=0.913]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=509, loss=0.548]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=510, loss=0.761]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=511, loss=0.744]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=512, loss=0.667]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=513, loss=0.704]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=514, loss=0.519]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=515, loss=0.644]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=516, loss=0.86] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=517, loss=1]    \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=518, loss=0.667]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=519, loss=0.446]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=520, loss=0.529]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=521, loss=0.607]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=522, loss=0.972]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=523, loss=0.929]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=524, loss=0.669]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=525, loss=0.546]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=526, loss=0.526]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=527, loss=0.586]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=528, loss=0.708]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=529, loss=0.74] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=530, loss=0.686]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=531, loss=0.531]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=532, loss=0.662]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=533, loss=0.724]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=534, loss=0.565]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=535, loss=0.677]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=536, loss=0.643]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=537, loss=0.703]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=538, loss=1.08] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=539, loss=0.568]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=540, loss=0.527]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=541, loss=0.472]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=542, loss=0.868]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=543, loss=0.664]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=544, loss=0.769]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=545, loss=0.56] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=546, loss=0.635]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=547, loss=0.544]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=548, loss=0.592]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=549, loss=0.525]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=550, loss=0.772]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=551, loss=0.843]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=552, loss=0.919]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=553, loss=0.507]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=554, loss=0.478]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=555, loss=0.469]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=556, loss=0.534]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=557, loss=0.819]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=558, loss=0.68] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=559, loss=0.97] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=560, loss=0.501]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=561, loss=0.574]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=562, loss=0.481]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=563, loss=0.829]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=564, loss=0.697]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=565, loss=0.558]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=566, loss=0.578]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=567, loss=0.428]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=568, loss=0.587]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=569, loss=0.544]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=570, loss=0.625]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=571, loss=0.768]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=572, loss=0.703]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=573, loss=0.463]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=574, loss=0.57] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=575, loss=1.06] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=576, loss=0.711]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=577, loss=0.452]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=578, loss=0.388]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=579, loss=0.544]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=580, loss=0.524]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=581, loss=0.602]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=582, loss=0.611]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=583, loss=1.27] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=584, loss=0.501]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=585, loss=0.554]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=586, loss=0.411]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=587, loss=0.509]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=588, loss=0.829]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=589, loss=0.504]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=590, loss=0.445]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=591, loss=0.561]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=592, loss=0.517]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=593, loss=0.564]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=594, loss=0.631]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=595, loss=0.583]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=596, loss=0.809]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=597, loss=0.489]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=598, loss=0.381]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=599, loss=0.615]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=600, loss=0.957]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=601, loss=0.523]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.32it/s, epoch=602, loss=0.414]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=603, loss=0.637]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=604, loss=0.635]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=605, loss=0.515]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=606, loss=0.571]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=607, loss=0.665]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=608, loss=0.56] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=609, loss=0.63] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=610, loss=0.459]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=611, loss=0.49] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=612, loss=0.789]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=613, loss=0.716]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=614, loss=0.593]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=615, loss=0.406]\n",
      "100%|██████████| 36/36 [00:12<00:00,  2.78it/s, epoch=616, loss=0.451]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=617, loss=0.602]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=618, loss=0.485]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=619, loss=0.621]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=620, loss=0.572]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=621, loss=0.63] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=622, loss=0.474]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=623, loss=0.521]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=624, loss=0.519]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=625, loss=0.879]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=626, loss=0.456]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=627, loss=0.44] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=628, loss=0.483]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=629, loss=0.457]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=630, loss=0.504]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=631, loss=0.911]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=632, loss=0.483]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=633, loss=0.572]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=634, loss=0.407]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=635, loss=0.577]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=636, loss=0.47] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=637, loss=0.501]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=638, loss=0.567]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=639, loss=0.544]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=640, loss=0.79] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=641, loss=0.431]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=642, loss=0.36] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=643, loss=0.515]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=644, loss=0.777]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=645, loss=0.673]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=646, loss=0.476]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=647, loss=0.482]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=648, loss=0.391]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=649, loss=0.307]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=650, loss=0.677]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=651, loss=0.661]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=652, loss=0.522]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=653, loss=0.467]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=654, loss=0.431]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=655, loss=0.662]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=656, loss=0.535]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=657, loss=0.723]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.28it/s, epoch=658, loss=0.591]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=659, loss=0.41] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=660, loss=0.45] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=661, loss=0.86] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=662, loss=0.585]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=663, loss=0.432]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=664, loss=0.357]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=665, loss=0.465]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=666, loss=0.55] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=667, loss=0.468]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=668, loss=0.644]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=669, loss=0.641]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=670, loss=0.465]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=671, loss=0.665]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=672, loss=0.428]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=673, loss=0.439]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=674, loss=0.75] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=675, loss=0.766]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=676, loss=0.364]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=677, loss=0.293] \n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=678, loss=0.506]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=679, loss=0.599]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=680, loss=0.473]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=681, loss=0.406]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=682, loss=0.403]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.31it/s, epoch=683, loss=0.577]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=684, loss=0.482]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=685, loss=0.639]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.30it/s, epoch=686, loss=0.993]\n",
      "100%|██████████| 36/36 [00:10<00:00,  3.29it/s, epoch=687, loss=0.462]\n",
      "  6%|▌         | 2/36 [00:00<00:10,  3.20it/s, epoch=688, loss=0.0321]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-e4d969383ecf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-344569b1c15a>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msequence_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msequence_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5266\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5267\u001b[0m         \"\"\"\n\u001b[0;32m-> 5268\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5269\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5270\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4547\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4549\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4551\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4629\u001b[0m         \u001b[0mbm_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0maxis_num\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4630\u001b[0;31m         new_mgr = self._mgr.reindex_indexer(\n\u001b[0m\u001b[1;32m   4631\u001b[0m             \u001b[0mnew_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4632\u001b[0m             \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             new_blocks = self._slice_take_blocks_ax0(\n\u001b[0m\u001b[1;32m    741\u001b[0m                 \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[0;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    896\u001b[0m                             \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m                         \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m                         \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;31m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m         new_values = algos.take_nd(\n\u001b[0m\u001b[1;32m    946\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/array_algos/take.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_take_nd_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/array_algos/take.py\u001b[0m in \u001b[0;36m_take_nd_ndarray\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflip_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "NUM_EPOCHS = 1000\n",
    "\n",
    "model.train() # put model in training mode\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "  \n",
    "  loop = tqdm(train_loader, position=0, leave=True)\n",
    "  \n",
    "  running_loss = 0.0\n",
    "  \n",
    "  for (batch, labels) in loop:\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    model.to('cuda')\n",
    "    output = model.forward(batch.to('cuda'))\n",
    "\n",
    "    var = torch.ones(output.shape).to('cuda')\n",
    "    loss = loss_function(output.to('cuda'), labels.to('cuda'), var)\n",
    "#     loss = loss_function(output.to('cuda'), labels.to('cuda'))\n",
    "    loss.to('cuda')\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item()\n",
    "    loop.set_postfix(epoch=epoch, loss=running_loss)\n",
    "    \n",
    "    if running_loss < 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = nn.Sequential(\n",
    "    nn.GRU(features_size, hiddenSize, num_layers=1, batch_first=True),\n",
    "    nn.Sequential(\n",
    "      extract_tensor(),\n",
    "      nn.Linear(hiddenSize, int(hiddenSize/2)),\n",
    "      nn.Linear(int(hiddenSize/2), 1),\n",
    "    )\n",
    ") # we do not specify ``weights``, i.e. create untrained model\n",
    "model1.load_state_dict(torch.load('model_weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): GRU(22, 128, batch_first=True)\n",
       "  (1): Sequential(\n",
       "    (0): extract_tensor()\n",
       "    (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.eval().to('cuda') # put model in evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max error 8.200480461120605, min error 0.03059709072113037, correct 0.51953125\n",
      "max error 7.6985907554626465, min error 0.0076766908168792725, correct 0.5384615063667297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "loop = tqdm(test_loader, position=0, leave=True)\n",
    "\n",
    "for (batch, labels) in loop:\n",
    "    output = model1.forward(batch.to('cuda'))\n",
    "    count = torch.count_nonzero(nn.functional.relu(labels.to('cuda') - output.to('cuda'), inplace=True))\n",
    "    abs_error = (labels.to('cuda') - output.to('cuda')).abs()\n",
    "#     print(labels, output, labels.to('cuda') - output.to('cuda'))\n",
    "    print(f'max error {torch.max(abs_error)}, min error {torch.min(abs_error)}, correct {count / labels.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
